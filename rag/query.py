#!/usr/bin/env python3
"""
RAG æŸ¥è¯¢å·¥å…· - æœè£…ä¾›åº”é“¾ç®¡ç†ç³»ç»Ÿ
=================================
ä»å·²æ„å»ºçš„ç´¢å¼•ä¸­æ£€ç´¢ä¸é—®é¢˜æœ€ç›¸å…³çš„æ–‡æ¡£ç‰‡æ®µã€‚

ç”¨æ³•ï¼š
    python3 rag/query.py "å¦‚ä½•æ·»åŠ ä¸€ä¸ªæ–°çš„Orchestrator"
    python3 rag/query.py "æ‰«ç é˜²é‡å¤ç®—æ³•" --top 5
    python3 rag/query.py "å¼¹çª—å°ºå¯¸è§„èŒƒ" --type doc
    python3 rag/query.py "ç”Ÿäº§è®¢å•API" --brief
"""

import json
import re
import sys
import argparse
from pathlib import Path

ROOT = Path(__file__).parent.parent
INDEX_FILE = ROOT / "rag" / "index.json"
TOKENS_FILE = ROOT / "rag" / "tokens.json"


def tokenize(text: str) -> list[str]:
    try:
        import jieba
        jieba.setLogLevel(60)
        text = re.sub(r'([a-z])([A-Z])', r'\1 \2', text)
        tokens = list(jieba.cut(text, cut_all=False))
        return [t.strip().lower() for t in tokens if len(t.strip()) > 1]
    except ImportError:
        tokens = re.findall(r'[\u4e00-\u9fff]+|[a-zA-Z][a-zA-Z0-9_]*', text)
        return [t.lower() for t in tokens if len(t) > 1]


def load_index():
    if not INDEX_FILE.exists():
        print("âŒ ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œï¼špython3 rag/build_index.py")
        sys.exit(1)
    chunks = json.loads(INDEX_FILE.read_text(encoding="utf-8"))
    tokens = json.loads(TOKENS_FILE.read_text(encoding="utf-8"))
    return chunks, tokens


def search(query: str, chunks: list, tokens: list, top_n: int = 5, filter_type: str = None) -> list[dict]:
    from rank_bm25 import BM25Okapi

    query_tokens = tokenize(query)
    if not query_tokens:
        return []

    # copilot-instructions.md æ˜¯ summary æ–‡ä»¶ï¼Œå¯†åº¦æé«˜ä¼šéœ¸æ¦œ
    # é™æƒè‡³ 0.4ï¼ˆä»å¯å‡ºç°ï¼Œä½†ä¸ä¼šæ¯æ¬¡éƒ½æ’ç¬¬ä¸€ï¼‰
    SUMMARY_SOURCES = {".github/copilot-instructions.md"}
    SUMMARY_WEIGHT = 0.4

    # å¯é€‰ï¼šæŒ‰ç±»å‹è¿‡æ»¤
    if filter_type:
        indices = [i for i, c in enumerate(chunks) if filter_type in c.get("type", "")]
        filtered_tokens = [tokens[i] for i in indices]
        filtered_chunks = [chunks[i] for i in indices]
    else:
        indices = list(range(len(chunks)))
        filtered_tokens = tokens
        filtered_chunks = chunks

    if not filtered_tokens:
        return []

    bm25 = BM25Okapi(filtered_tokens)
    scores = bm25.get_scores(query_tokens)

    # å¯¹ summary æ–‡ä»¶é™æƒ
    for i, chunk in enumerate(filtered_chunks):
        if chunk.get("source", "") in SUMMARY_SOURCES:
            scores[i] *= SUMMARY_WEIGHT

    # å– top_n
    top_indices = sorted(range(len(scores)), key=lambda i: scores[i], reverse=True)[:top_n]

    results = []
    for idx in top_indices:
        if scores[idx] < 0.01:
            continue
        chunk = filtered_chunks[idx].copy()
        chunk["score"] = round(float(scores[idx]), 3)
        results.append(chunk)

    return results


def display(results: list[dict], brief: bool = False):
    if not results:
        print("âš ï¸  æ²¡æœ‰æ‰¾åˆ°ç›¸å…³å†…å®¹")
        return

    for i, r in enumerate(results, 1):
        score = r.get("score", 0)
        source = r.get("source", "")
        title = r.get("title", "")
        rtype = r.get("type", "")
        content = r.get("content", "")

        bar = "â–ˆ" * min(int(score * 3), 10)
        print(f"\n{'â”€'*60}")
        print(f"#{i}  [{rtype}] {source}")
        if title:
            print(f"    ğŸ“Œ {title}")
        print(f"    ç›¸å…³åº¦: {bar} {score}")
        print(f"{'â”€'*60}")

        if brief:
            # åªæ˜¾ç¤ºå‰ 200 å­—
            preview = content[:200].replace('\n', ' ')
            print(f"{preview}{'...' if len(content) > 200 else ''}")
        else:
            print(content[:600])
            if len(content) > 600:
                print(f"... [å…± {len(content)} å­—ï¼Œæˆªæ–­æ˜¾ç¤º]")


def main():
    parser = argparse.ArgumentParser(description="æŸ¥è¯¢æœè£…é¡¹ç›®çŸ¥è¯†åº“")
    parser.add_argument("query", help="æ£€ç´¢é—®é¢˜ï¼Œä¾‹å¦‚ï¼šå¦‚ä½•æ·»åŠ Orchestrator")
    parser.add_argument("--top", type=int, default=5, help="è¿”å›ç»“æœæ•°é‡ï¼ˆé»˜è®¤5ï¼‰")
    parser.add_argument("--type", dest="filter_type", default=None,
                        help="æŒ‰ç±»å‹è¿‡æ»¤ï¼šdoc / orchestrator / controller / api / store / util")
    parser.add_argument("--brief", action="store_true", help="åªæ˜¾ç¤ºæ‘˜è¦ï¼ˆå‰200å­—ï¼‰")

    args = parser.parse_args()

    print(f"\nğŸ” æŸ¥è¯¢ï¼š{args.query}")
    if args.filter_type:
        print(f"   è¿‡æ»¤ç±»å‹ï¼š{args.filter_type}")
    print()

    chunks, tokens = load_index()
    results = search(args.query, chunks, tokens, top_n=args.top, filter_type=args.filter_type)
    display(results, brief=args.brief)

    print(f"\nå…±æ‰¾åˆ° {len(results)} æ¡ç›¸å…³å†…å®¹ï¼ˆç´¢å¼•å…± {len(chunks)} chunksï¼‰\n")


if __name__ == "__main__":
    main()
